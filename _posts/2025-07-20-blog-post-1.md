---
title: 'Unitary Foundation WERQSHOP'
date: 2025-07-20
permalink: /posts/2025/07/
tags:
  - Unitary Foundation
  - Conference
  - Quantum Computing
---

WERQSHOP
======

This past week, I had the opportunity to attend the Unitary Foundation's [Workshop on Error Resilience in Quantum Computing](https://unitary.foundation/posts/2025_werqshop/) hosted by NYU. It was a nice change of pace to attend a conference without the pressure of presenting or travelling, and was a great opportunity to learn more about a subfield which I have only interacted with as a user rather than a researcher. Though niche in scope, I found the conference was thankfully still accesible and engaging. This was aided by there being present a good balance of industry and academia that made for great networking and some excellent breakout discussion sessions, which is something I wish more conferences would implement! A major thank you to the IonQ team for being excellent discussion facilitators.

Being less of an error resilience researcher, Day Two's focus on error mitigation in practice was more engaging to me. As someone with a distributed quantum computing background, my favourite presentation was no surprise. From the University of Edinburgh, María Gragera Garcés presentation, titled 'Scaling Quantum Error Mitigation in the Age of Distributed Quantum Computation' was very informative. It was also the first time I've seen my own paper referenced in someone elses presentation! Using hypergraphs to represent quantum circuits and then employing graph cutting heuristics to implement more resilient distributed algorithms definitely got me thinking about ways to optimize my current research. With the obvious difficulties in finding truely optimal circuit cuts without large classical overhead, I was left curious about the potential impact of employing more 'bottom-up' circuit reconfigurations with the eventual graph cut in mind on error resilience. The only thing clear is that there is certainly no shortage of futher research opportunities in distributed quantum computing!

What I'm Taking Away
------

While there are no shortage of very smart people who have developed very sophisticated error mitigation techniques, many presenters made clear the limitations of such techniques as they scale with circuit size. This was most clearly laid out in the work by Algorithmiq's Matea Leahy, on scalable tensor-network based error mitigation. I certainly appreciate such techniques, particularly when they are easily available and simple for users through cloud platforms such as IBM's Qiskit framework, the backend and future of which were well covered by Sam Ferracin's presentation, but I am left wondering about the role such techniques can play in the long run. Perhaps cryptographic protocols with their lower requirements in terms of circuit area are where such error mitigation techniques are most useful, but for the immediate term, I still see hardware challenges, and physical qubit quality as the most important part of the quantum computing stack to address if fault-tolerance is ever to be achieved.


------